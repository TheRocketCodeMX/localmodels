#!/bin/bash

# Pull all models script
# This script downloads all the configured models for the multi-model API

echo "üöÄ Downloading all configured models..."
echo "‚ö†Ô∏è This process may take 30+ minutes depending on your internet connection"
echo "‚ö†Ô∏è Make sure you have enough disk space (>100GB recommended)"

# Models to download
MODELS=(
    "gpt-oss:20b"
    "qwen3:30b" 
    "devstral"
    "gemma3"
)

# Check if Ollama is running
if ! curl -s http://localhost:11434/api/tags > /dev/null; then
    echo "‚ùå Ollama is not running on localhost:11434"
    echo "   Make sure Ollama service is started first"
    exit 1
fi

echo "‚úÖ Ollama service detected"

# Download each model
for model in "${MODELS[@]}"; do
    echo ""
    echo "üì• Downloading $model..."
    
    # Check if model already exists
    if curl -s http://localhost:11434/api/tags | grep -q "$model"; then
        echo "‚úÖ $model already exists, skipping"
        continue
    fi
    
    # Pull the model
    if curl -X POST http://localhost:11434/api/pull \
        -H "Content-Type: application/json" \
        -d "{\"name\":\"$model\", \"stream\": false}"; then
        echo "‚úÖ $model downloaded successfully"
    else
        echo "‚ùå Failed to download $model"
        echo "   You can try downloading manually with: ollama pull $model"
    fi
done

echo ""
echo "üéâ All models download process completed!"
echo "üìã To see downloaded models run: ollama list"